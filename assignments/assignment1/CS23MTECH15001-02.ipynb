{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "186e4512-2dbe-4958-82f4-1ebc0f54f790",
   "metadata": {},
   "source": [
    "# Assignment 1 CS5803\n",
    "\n",
    "It includes the solution to all questions of the Assignment 1 of CS5803 Natural Language processing course\n",
    "\n",
    "# TEAM MEMBERS\n",
    "\n",
    "## Group No 2\n",
    "Abhinav Kumar Jha (cs23mtech15001@iith.ac.in)         \n",
    "Shriram Pradeep (cs23mtech15020@iith.ac.in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce08f70-b869-4ec5-8c35-47780873dedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import string\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6897c2d-b708-4b68-a38a-3e9fc445ed1e",
   "metadata": {},
   "source": [
    "# Question 1.1\n",
    "\n",
    "Implement BLEU Score metric. Pre-process the text by lower-casing the text and removing punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a795b213-b167-4c71-9723-c2ad928f690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BleuScore:\n",
    "    \"\"\"\n",
    "    Class to implement bleu score\n",
    "    \"\"\"\n",
    "    def __init__(self,max_order=4):\n",
    "        \"\"\"\n",
    "        Initializes variables to default values\n",
    "        \"\"\"\n",
    "        self.results_dict = {}\n",
    "        self.max_order = max_order\n",
    "        self.matches_by_order = [0] * self.max_order\n",
    "        self.possible_matches_by_order = [0] * self.max_order\n",
    "        self.precisions = [0] * self.max_order\n",
    "        self.reference_text_length = 0\n",
    "        self.translation_text_length = 0\n",
    "    \n",
    "    def preprocess_text(self,text):\n",
    "        \"\"\"\n",
    "        Preprocess the text by converting it into lower case and removes punctuation\n",
    "        \"\"\"\n",
    "        # Convert the text to lowercase\n",
    "        text = text.lower()\n",
    "        # Remove punctuation\n",
    "        text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "        return text\n",
    "    \n",
    "    \n",
    "    def generate_ngrams(self,text_list, max_order=4):\n",
    "        \"\"\"Extracts all n-grams up to a given maximum order from an input segment.\n",
    "    \n",
    "        :param text_list: list of text tokens from which n-grams will be extracted.\n",
    "        :param max_order: maximum length in tokens of the n-grams returned by this methods.\n",
    "        \n",
    "        :returns The all n-grams upto max_order in segment with a count of how many times each n-gram occurred.\n",
    "        \"\"\"\n",
    "        ngram_counts = collections.Counter()\n",
    "        for order in range(1, max_order + 1):\n",
    "            for i in range(0, len(text_list) - order + 1):\n",
    "                # For ngram to be hashable.\n",
    "                ngram = tuple(text_list[i : i + order])\n",
    "                ngram_counts[ngram] += 1\n",
    "        return ngram_counts\n",
    "\n",
    "    def print_bleu_score(self,bleu_info):\n",
    "        \"\"\"\n",
    "        prints the bleu score values in more readable format\n",
    "        :args: bleu_info: Dictionary containing the bleu score,geometric mean,precision values and brevity penalty calculated\n",
    "        \"\"\"\n",
    "        print(\"*\"*50)\n",
    "        print(\"\\nPrecision:\")\n",
    "        for ngram, score in bleu_info['precision'].items():\n",
    "            print(\"{:8s}: {:.4f}\".format(ngram.capitalize(), score))\n",
    "        print(\"Geometric Mean: {:.4f}\".format(bleu_info['geometric_mean']))\n",
    "        print(\"Brevity Penalty: {:.4f}\".format(bleu_info['brevity_penalty']))\n",
    "        print(\"\\nBLEU Score: {:.4f}\".format(bleu_info['bleu_score']))\n",
    "        \n",
    "        print(\"*\"*50)\n",
    "    \n",
    "    def get_bleu_score(\n",
    "        self,translation_text, reference_text_list, max_order=4, smooth=True\n",
    "    ):\n",
    "        \"\"\"Computes BLEU score of translated segments against one or more references.\n",
    "        \n",
    "        :param translation_text: List of translations to score.\n",
    "        :param reference_text_list: List of reference text for translation text.\n",
    "        :param max_order: Maximum n-gram order to use when computing BLEU score.\n",
    "        :param smooth: Boolean value for whether or not to apply smoothing\n",
    "        \n",
    "        :returns: BLEU score, geometric mean, n-gram precisions, and brevity penalty.\n",
    "        \"\"\"\n",
    "    \n",
    "        translation_text_list = self.preprocess_text(translation_text).split()\n",
    "        reference_text_list = [self.preprocess_text(reference_sentence).split() for reference_sentence in reference_text_list]\n",
    "\n",
    "        # Calculate r\n",
    "        self.reference_text_length += min(len(ref) for ref in reference_text_list)\n",
    "        # Calculate c\n",
    "        self.translation_text_length = len(translation_text_list)\n",
    "        \n",
    "        # Finds the maximum ngram count in references\n",
    "        # The | operator computes the maximum reference count as in the original paper.\n",
    "        # For any instance of n-grams, we takes its max count among all references.\n",
    "        reference_ngram_counts = collections.Counter()\n",
    "        for reference_text in reference_text_list:\n",
    "            reference_ngram_counts |= self.generate_ngrams(reference_text, max_order)\n",
    "        translation_ngram_counts = self.generate_ngrams(translation_text_list, max_order)\n",
    "    \n",
    "        # Clips translation ngram count with maximum ngram count in reference\n",
    "        # The clipping prevents meaningless translation consisting of many repeated words being overestimated,\n",
    "        overlap = translation_ngram_counts & reference_ngram_counts\n",
    "        for ngram in overlap:\n",
    "            self.matches_by_order[len(ngram) - 1] += overlap[ngram]\n",
    "    \n",
    "        # Computes the counts of all n-grams ranging from 1 to max_order in a translation,\n",
    "        # This term serves as the normalizer in the modified-ngrams-precision\n",
    "        for order in range(1, max_order + 1):\n",
    "            possible_matches = len(translation_text_list) - order + 1\n",
    "            if possible_matches > 0:\n",
    "                self.possible_matches_by_order[order - 1] += possible_matches\n",
    "\n",
    "        # Compute modified n-grams precision\n",
    "        for i in range(self.max_order):\n",
    "            if smooth:\n",
    "                smoothed_match_value = (self.matches_by_order[i] + 0.1) if self.matches_by_order[i] == 0 else self.matches_by_order[i]\n",
    "                self.precisions[i] = smoothed_match_value / self.possible_matches_by_order[i] \\\n",
    "                                                        if self.possible_matches_by_order[i] > 0 else 0.0\n",
    "            else:\n",
    "                self.precisions[i] = self.matches_by_order[i] / self.possible_matches_by_order[i] \\\n",
    "                                                            if self.possible_matches_by_order[i] > 0 else 0.0\n",
    "        \n",
    "        # Calculate geometric mean\n",
    "        if min(self.precisions) > 0:\n",
    "            precision_log_sum = sum((1.0 / self.max_order) * math.log(precision) for precision in self.precisions)\n",
    "            geo_mean = math.exp(precision_log_sum)\n",
    "        else:\n",
    "            geo_mean = 0\n",
    "        \n",
    "        # Compute brevity penalty\n",
    "        ratio = float(self.translation_text_length) / self.reference_text_length\n",
    "        brevity_penalty = min(1.0, math.exp(1 - 1.0 / ratio))\n",
    "        \n",
    "        # Compute BLEU score\n",
    "        bleu = geo_mean * brevity_penalty\n",
    "\n",
    "        precisions_dict = {\n",
    "            'unigram':self.precisions[0],\n",
    "            'bigram':self.precisions[1],\n",
    "            'trigram':self.precisions[2],\n",
    "            '4-gram':self.precisions[3]\n",
    "        }\n",
    "        self.results_dict['bleu_score'] = bleu\n",
    "        self.results_dict['geometric_mean'] = geo_mean\n",
    "        self.results_dict['precision'] = precisions_dict\n",
    "        self.results_dict['brevity_penalty'] = brevity_penalty\n",
    "        \n",
    "        return self.results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d903a4-14ae-4c18-8b2e-a2d04be4aaef",
   "metadata": {},
   "source": [
    "# Question 1.2\n",
    "\n",
    "Use the bleau score implementation to find BLEU Score when      \n",
    "`x = The boys were playing happily on the ground.` \n",
    "and     \n",
    "`y = The boys were playing football on the field.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d98ff289-524d-4681-8223-4caa9068135e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "\n",
      "Precision:\n",
      "Unigram : 0.7500\n",
      "Bigram  : 0.5714\n",
      "Trigram : 0.3333\n",
      "4-gram  : 0.2000\n",
      "Geometric Mean: 0.4111\n",
      "Brevity Penalty: 1.0000\n",
      "\n",
      "BLEU Score: 0.4111\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "translation_text = 'The boys were playing happily on the ground.'\n",
    "reference_text_list  = ['The boys were playing football on the field']\n",
    "\n",
    "bleu_score_obj = BleuScore()\n",
    "score = bleu_score_obj.get_bleu_score(\n",
    "    translation_text=translation_text,\n",
    "    reference_text_list=reference_text_list\n",
    ")\n",
    "bleu_score_obj.print_bleu_score(score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53053104-e134-4a7c-ab62-2c98dabcfea4",
   "metadata": {},
   "source": [
    "# Question 1.3\n",
    "\n",
    "Can you explain why we are taking minimum in numerator in equation 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05578b8a-3b19-4a27-8515-89f3ec124e3e",
   "metadata": {},
   "source": [
    "## Answer 1.3\n",
    "\n",
    "\n",
    "Machine Translation systems may overgenerate reasonable words resulting in translations with high precisions but bad translations if one does not clip the count of each candidate word by it's maximum reference count.\n",
    "\n",
    "For e.g \n",
    "```\n",
    "Candidate: the the the the the the the. \n",
    "\n",
    "Reference 1: The cat is on the mat.\n",
    "Reference 2: There is a cat on the mat.\n",
    "\n",
    "Standard Unigram precision is 7/7.\n",
    "Modified Unigram Precision = 2/7.\n",
    "\n",
    "```\n",
    "\n",
    "Therefore to produce better translations for a particular value of n we take the min to clip the total count of each candidate word by it's maximum count present in any reference translations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3bbce8-41c4-43f3-afd5-999a16f7a033",
   "metadata": {},
   "source": [
    "# Question 1.4\n",
    "\n",
    "Use your Bleu score implementation to find BLEU Score between any 5 sentence pairs and\n",
    "\n",
    "Explain what are potential disadvantages of using the BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72a66de2-8245-4f86-aadc-12fb341529c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Translation text \n",
      " The cat is sitting on the mat \n",
      "Reference Text \n",
      " ['The cat is on the mat']\n",
      "Bleu Score computed is \n",
      " \n",
      "**************************************************\n",
      "\n",
      "Precision:\n",
      "Unigram : 0.8571\n",
      "Bigram  : 0.6667\n",
      "Trigram : 0.4000\n",
      "4-gram  : 0.0250\n",
      "Geometric Mean: 0.2749\n",
      "Brevity Penalty: 1.0000\n",
      "\n",
      "BLEU Score: 0.2749\n",
      "**************************************************\n",
      "\n",
      "\n",
      "For Translation text \n",
      " The cat is sleeping on the couch. \n",
      "Reference Text \n",
      " ['The cat is sleeping on the sofa.']\n",
      "Bleu Score computed is \n",
      " \n",
      "**************************************************\n",
      "\n",
      "Precision:\n",
      "Unigram : 0.8571\n",
      "Bigram  : 0.8333\n",
      "Trigram : 0.8000\n",
      "4-gram  : 0.7500\n",
      "Geometric Mean: 0.8091\n",
      "Brevity Penalty: 1.0000\n",
      "\n",
      "BLEU Score: 0.8091\n",
      "**************************************************\n",
      "\n",
      "\n",
      "For Translation text \n",
      " I enjoy listening to music. \n",
      "Reference Text \n",
      " ['I like to listen to music.']\n",
      "Bleu Score computed is \n",
      " \n",
      "**************************************************\n",
      "\n",
      "Precision:\n",
      "Unigram : 0.6000\n",
      "Bigram  : 0.2500\n",
      "Trigram : 0.0333\n",
      "4-gram  : 0.0500\n",
      "Geometric Mean: 0.1257\n",
      "Brevity Penalty: 0.8187\n",
      "\n",
      "BLEU Score: 0.1029\n",
      "**************************************************\n",
      "\n",
      "\n",
      "For Translation text \n",
      " The weather is beautiful today. \n",
      "Reference Text \n",
      " ['Today weather is lovely.']\n",
      "Bleu Score computed is \n",
      " \n",
      "**************************************************\n",
      "\n",
      "Precision:\n",
      "Unigram : 0.6000\n",
      "Bigram  : 0.2500\n",
      "Trigram : 0.0333\n",
      "4-gram  : 0.0500\n",
      "Geometric Mean: 0.1257\n",
      "Brevity Penalty: 1.0000\n",
      "\n",
      "BLEU Score: 0.1257\n",
      "**************************************************\n",
      "\n",
      "\n",
      "For Translation text \n",
      " She is reading a book in the garden. \n",
      "Reference Text \n",
      " ['She reads a book in the garden.']\n",
      "Bleu Score computed is \n",
      " \n",
      "**************************************************\n",
      "\n",
      "Precision:\n",
      "Unigram : 0.7500\n",
      "Bigram  : 0.5714\n",
      "Trigram : 0.5000\n",
      "4-gram  : 0.4000\n",
      "Geometric Mean: 0.5411\n",
      "Brevity Penalty: 1.0000\n",
      "\n",
      "BLEU Score: 0.5411\n",
      "**************************************************\n",
      "\n",
      "\n",
      "For Translation text \n",
      " He ate a delicious meal at the restaurant. \n",
      "Reference Text \n",
      " ['He enjoyed a tasty meal at the restaurant.']\n",
      "Bleu Score computed is \n",
      " \n",
      "**************************************************\n",
      "\n",
      "Precision:\n",
      "Unigram : 0.7500\n",
      "Bigram  : 0.4286\n",
      "Trigram : 0.3333\n",
      "4-gram  : 0.2000\n",
      "Geometric Mean: 0.3826\n",
      "Brevity Penalty: 1.0000\n",
      "\n",
      "BLEU Score: 0.3826\n",
      "**************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "translation_text_list = ['The cat is sitting on the mat',\n",
    "                         'The cat is sleeping on the couch.',\n",
    "                        'I enjoy listening to music.',\n",
    "                        'The weather is beautiful today.',\n",
    "                        'She is reading a book in the garden.',\n",
    "                        'He ate a delicious meal at the restaurant.'\n",
    "                        ]\n",
    "\n",
    "references_text_list  = [\n",
    "                            ['The cat is on the mat'],\n",
    "                            ['The cat is sleeping on the sofa.'],\n",
    "                            ['I like to listen to music.'],\n",
    "                            ['Today weather is lovely.'],\n",
    "                            ['She reads a book in the garden.'],\n",
    "                            ['He enjoyed a tasty meal at the restaurant.']\n",
    "                       ]\n",
    "\n",
    "\n",
    "for (translation_text,reference_text) in zip(translation_text_list,references_text_list):\n",
    "    bleu_score_obj = BleuScore()\n",
    "    \n",
    "    bleu_score = bleu_score_obj.get_bleu_score(\n",
    "        translation_text=translation_text,\n",
    "        reference_text_list=reference_text\n",
    "    )\n",
    "    print(\"For Translation text \\n {0} \\nReference Text \\n {1}\".format(translation_text,reference_text))\n",
    "    print(\"Bleu Score computed is \\n \")\n",
    "    bleu_score_obj.print_bleu_score(bleu_score)\n",
    "    print()\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8900c76-9028-4c8c-bb07-20c020d2cf60",
   "metadata": {},
   "source": [
    "###  Disadvantages of Bleu Score\n",
    "\n",
    "\n",
    "1. **Inability to Capture Meaning**: BLEU does not measure the semantic meaning of translations. It cannot differentiate between translations that convey the intended meaning accurately and those that do not\n",
    "2. **Limited Vocabulary Coverage**: BLEU Score considers only exact matches of n-grams between translations and references. It penalizes translations for using synonyms or paraphrasing, which may be valid translations but not identical to the reference text.\n",
    "3. **Insensitive to Structural Differences**: BLEU treats all n-grams equally regardless of their position in the sentence. It does not consider differences in word order or sentence structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a0e3a-633f-4444-b56b-a92e06ec349c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
