{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iX_647zWX2yv",
    "outputId": "a05a45e1-0d1e-4ce4-8d69-f7d261740e11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.22.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "import os\n",
    "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0nRf6-VWbVz"
   },
   "source": [
    "\n",
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SDm4aaSaWTRN"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizerFast\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQBOQuJuWgN2"
   },
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sYs4vWT6Wael"
   },
   "outputs": [],
   "source": [
    "class LoadFormatData:\n",
    "    \"\"\"\n",
    "    Class to load and format data from the SWAG dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, train_data_size=1000, batch_size=32):\n",
    "        \"\"\"\n",
    "        Initialize the DataLoader with specified data size and batch size.\n",
    "\n",
    "        :param train_data_size: Size of the dataset to load.\n",
    "        :param batch_size: Batch size for DataLoader.\n",
    "        \"\"\"\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased', use_fast=True)\n",
    "        self.dataset = load_dataset('swag', 'regular')\n",
    "\n",
    "        # Limit dataset size\n",
    "        self.dataset['train'] = self.dataset['train'].select(range(train_data_size))\n",
    "        validation_data_size = int(train_data_size*0.2)\n",
    "        self.dataset['validation'] = self.dataset['validation'].select(range(validation_data_size))\n",
    "\n",
    "        # Tokenize and encode the dataset\n",
    "        self.encoded_data = self.dataset.map(self.tokenize_data_batched, batched=True)\n",
    "        self.train_data = self.encoded_data['train']\n",
    "        self.validation_data = self.encoded_data['validation']\n",
    "\n",
    "    def tokenize_data_batched(self, batch):\n",
    "        \"\"\"\n",
    "        Tokenize a batch of data from the SWAG dataset.\n",
    "\n",
    "        :param batch: Batch object containing the data.\n",
    "        :return: Tokenized data.\n",
    "        \"\"\"\n",
    "        swag_data = {\n",
    "            'sent1': batch['sent1'],\n",
    "            'sent2': batch['sent2'],\n",
    "            'ending0': batch['ending0'],\n",
    "            'ending1': batch['ending1'],\n",
    "            'ending2': batch['ending2'],\n",
    "            'ending3': batch['ending3'],\n",
    "            'label': batch['label']\n",
    "        }\n",
    "\n",
    "        # Convert dictionary to DataFrame\n",
    "        swag_data_df = pd.DataFrame(swag_data)\n",
    "\n",
    "        # Expand sentence headers to match the number of choices\n",
    "        ending_columns = ['ending0', 'ending1', 'ending2', 'ending3']\n",
    "        first_sentences = [context for context in swag_data_df['sent1'] for _ in range(4)]\n",
    "        second_sentences = [\n",
    "            \"{} {}\".format(header, swag_data_df[ending].iloc[i])\n",
    "            for i, header in enumerate(swag_data_df['sent2'])\n",
    "            for ending in ending_columns\n",
    "        ]\n",
    "\n",
    "        # Tokenize the sentences using the tokenizer\n",
    "        tokenized_batch = self.tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "\n",
    "        # Reshape tokenized examples\n",
    "        reshaped_tokenized = {}\n",
    "        for key, value in tokenized_batch.items():\n",
    "            reshaped_tokenized[key] = [value[i:i + 4] for i in range(0, len(value), 4)]\n",
    "\n",
    "        return reshaped_tokenized\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_batch(batch):\n",
    "        \"\"\"\n",
    "        Collate a batch of tokenized data.\n",
    "\n",
    "        :param batch: List of tokenized data.\n",
    "        :return: Padded and reshaped tokenized data with labels.\n",
    "        \"\"\"\n",
    "        batch_size = len(batch)\n",
    "        num_choices = 4\n",
    "\n",
    "        # Flatten features\n",
    "        flattened_features = [\n",
    "            {k: v[i] for k, v in feature.items() if k in [\"input_ids\", \"attention_mask\"]}\n",
    "            for feature in batch\n",
    "            for i in range(num_choices)\n",
    "        ]\n",
    "\n",
    "        # Padding using tokenizer\n",
    "        tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "        flattened_features_padded = tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # Reshape tokenized examples\n",
    "        for k, v in flattened_features_padded.items():\n",
    "            flattened_features_padded[k] = v.view(batch_size, num_choices, -1)\n",
    "\n",
    "        # Convert labels to tensor\n",
    "        labels = [feature['label'] for feature in batch]\n",
    "        flattened_features_padded[\"label\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        return flattened_features_padded\n",
    "\n",
    "    def get_train_loader(self):\n",
    "        \"\"\"\n",
    "        Get the DataLoader for the training dataset.\n",
    "\n",
    "        :return: Training DataLoader.\n",
    "        \"\"\"\n",
    "        return DataLoader(\n",
    "            self.train_data, batch_size=self.batch_size, collate_fn=LoadFormatData.collate_batch, shuffle=True\n",
    "        )\n",
    "\n",
    "    def get_validation_loader(self):\n",
    "        \"\"\"\n",
    "        Get the DataLoader for the training dataset.\n",
    "\n",
    "        :return: Validation DataLoader.\n",
    "        \"\"\"\n",
    "        return DataLoader(\n",
    "            self.validation_data, batch_size=self.batch_size, collate_fn=LoadFormatData.collate_batch, shuffle=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpQcmViHWj-F"
   },
   "source": [
    "# CUSTOM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "e-cq4JSdWoNY"
   },
   "outputs": [],
   "source": [
    "class CustomBertForMultipleChoice(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom BERT model for multiple choice tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name='bert-base-uncased'):\n",
    "        \"\"\"\n",
    "        Initialize the CustomBertForMultipleChoice model.\n",
    "\n",
    "        :param model_name: Name of the pretrained BERT model.\n",
    "        \"\"\"\n",
    "        super(CustomBertForMultipleChoice, self).__init__()\n",
    "\n",
    "        # Load pretrained BERT model\n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "\n",
    "        # Dropout layer for regularization\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        # Classifier layer\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Forward pass of the CustomBertForMultipleChoice model.\n",
    "\n",
    "        :param input_ids: Input token IDs.\n",
    "        :param attention_mask: Attention mask.\n",
    "        :return: Logits and predicted indices.\n",
    "        \"\"\"\n",
    "\n",
    "        # Flatten the input to (batch_size*num_choices, seq_length)\n",
    "        batch_size, num_choices, seq_length = input_ids.size()\n",
    "        flat_input_ids = input_ids.view(batch_size * num_choices, seq_length)\n",
    "        flat_attention_mask = attention_mask.view(batch_size * num_choices, seq_length)\n",
    "\n",
    "        # Pass through BERT model\n",
    "        outputs = self.bert(input_ids=flat_input_ids, attention_mask=flat_attention_mask)\n",
    "\n",
    "        # Extract pooled output and apply dropout\n",
    "        pooled_output = self.dropout(outputs.pooler_output)\n",
    "\n",
    "        # Pass through classifier\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        # Reshape logits to batch_size x num_choices\n",
    "        logits = logits.view(batch_size, num_choices)\n",
    "\n",
    "        # Get predicted indices\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "\n",
    "        return logits, predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-nRUzvIXL72"
   },
   "source": [
    "# TEST TRAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7GyP3BJiXMb2"
   },
   "outputs": [],
   "source": [
    "class SwagTrainer:\n",
    "    \"\"\"\n",
    "    Class for training and testing a model.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, train_loader,validation_loader, lr=1e-5):\n",
    "        \"\"\"\n",
    "        Initialize the SwagTrainer.\n",
    "\n",
    "        :param model: The model to train and test.\n",
    "        :param train_loader: DataLoader for training data.\n",
    "        :param validation_loader: Learning rate for the optimizer\n",
    "        :param lr:\n",
    "        \"\"\"\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = model.to(self.device)\n",
    "        self.train_loader = train_loader\n",
    "        self.validation_loader = validation_loader\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=lr)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def train(self, epochs=5):\n",
    "        \"\"\"\n",
    "        Train the model.\n",
    "\n",
    "        :param epochs: Number of epochs\n",
    "        :return: Number of training epochs\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            correct_predictions = 0\n",
    "            total_samples = 0\n",
    "\n",
    "            # Initialize tqdm to visualize progress\n",
    "            pbar = tqdm(total=len(self.train_loader), desc=f'Epoch {epoch+1}', unit='batch')\n",
    "\n",
    "            for batch in self.train_loader:\n",
    "                input_ids = batch[\"input_ids\"].to(self.device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(self.device)\n",
    "                labels = batch[\"label\"].to(self.device)\n",
    "\n",
    "                # Zero out gradients\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                logits, predicted = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "                # Calculate loss\n",
    "                loss = self.criterion(logits.view(-1, 4), labels.view(-1))\n",
    "\n",
    "                # Backward pass and optimization\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                # Calculate accuracy\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "            pbar.close()\n",
    "\n",
    "            avg_loss = total_loss / len(self.train_loader)\n",
    "            avg_accuracy = correct_predictions / total_samples\n",
    "            print(f'Epoch {epoch + 1}/{epochs},Training Loss: {avg_loss}, Training Accuracy: {avg_accuracy * 100:.2f}%')\n",
    "\n",
    "    def validation(self):\n",
    "        \"\"\"\n",
    "        Test the model on the test data.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        losses = []\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(self.validation_loader, desc=\"Validation\"):\n",
    "                input_ids = batch[\"input_ids\"].to(self.device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(self.device)\n",
    "                labels = batch[\"label\"].to(self.device)\n",
    "\n",
    "                # Forward pass\n",
    "                logits, predicted = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "                # Calculate loss\n",
    "                loss = self.criterion(logits.view(-1, 4), labels.view(-1))\n",
    "                losses.append(loss.item())\n",
    "\n",
    "                # Calculate accuracy\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "\n",
    "                # Append true labels and predicted labels\n",
    "                y_true.extend(labels.cpu().numpy())\n",
    "                y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "        val_accuracy = correct_predictions / total_samples\n",
    "        val_loss = sum(losses)/len(losses)\n",
    "        precision = precision_score(y_true, y_pred, average='macro')\n",
    "        recall = recall_score(y_true, y_pred, average='macro')\n",
    "        f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "        print(f'Validation Accuracy: {val_accuracy * 100:.2f}%')\n",
    "        print(f'Validation Precision: {precision * 100:.2f}%')\n",
    "        print(f'Validation Recall: {recall * 100:.2f}%')\n",
    "        print(f'Validation Loss: {val_loss * 100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNEe6HbWXlMR"
   },
   "source": [
    "# RUN CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194,
     "referenced_widgets": [
      "69e952df5f6b4c6a8b12e9229e5c3997",
      "47a3b3499e90463a955e17f46a2f2f08",
      "3ae29d6f0cbd4a5ba0d7cb2c5d17f470",
      "6a00776636574754a7763865838511c2",
      "25e8cbafbbf64880b2cd04a67393711f",
      "7389a7509192486c9e04a6e8ed62beee",
      "3ceff16007764ed88ce640d1c0d74741",
      "998d82a07cb24a5a8bd1218f4e60e4d0",
      "d7685ee79a414e13a791bc7fb271b76c",
      "69a02bfdcbf444fdbe8f55da0367d565",
      "d29e5203b57f40ce982460af7bae1683"
     ]
    },
    "id": "_J8JCH1bXmNg",
    "outputId": "8697a402-433e-4fd2-eb69-fb66718d9ccd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training size  73546\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e952df5f6b4c6a8b12e9229e5c3997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2941 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define data size and batch size\n",
    "dataset = load_dataset('swag', 'regular')\n",
    "print(\"Total training size \",len(dataset['train']))\n",
    "\n",
    "# Reducing the data size for training so as to do the training faster and it suits the memory restrictions as supported by Colab\n",
    "train_data_size = len(dataset['train'])//5\n",
    "\n",
    "batch_size = 32\n",
    "num_epoch = 3\n",
    "\n",
    "# Initialize and load the formatted data\n",
    "loader = LoadFormatData(train_data_size, batch_size)\n",
    "\n",
    "# Get DataLoader for training and validation\n",
    "train_loader = loader.get_train_loader()\n",
    "validation_loader = loader.get_validation_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vcN-4IpPY-hr",
    "outputId": "8a122126-922e-4788-9877-8ffe8fe9f7c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 460/460 [09:23<00:00,  1.23s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3,Training Loss: 0.9774736372025117, Training Accuracy: 59.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 460/460 [09:22<00:00,  1.22s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3,Training Loss: 0.6567545266255088, Training Accuracy: 74.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 460/460 [09:24<00:00,  1.23s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3,Training Loss: 0.435696672356647, Training Accuracy: 83.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 92/92 [00:46<00:00,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 74.94%\n",
      "Validation Precision: 74.95%\n",
      "Validation Recall: 74.93%\n",
      "Validation Loss: 68.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the custom BERT model for multiple choice\n",
    "model = CustomBertForMultipleChoice()\n",
    "\n",
    "# Initialize the trainer and tester with the model and data loaders\n",
    "swag_train_obj = SwagTrainer(model, train_loader,validation_loader)\n",
    "\n",
    "# Train the model\n",
    "swag_train_obj.train(epochs=num_epoch)\n",
    "\n",
    "swag_train_obj.validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PmAMBr5uC1Fv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "25e8cbafbbf64880b2cd04a67393711f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ae29d6f0cbd4a5ba0d7cb2c5d17f470": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_998d82a07cb24a5a8bd1218f4e60e4d0",
      "max": 2941,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d7685ee79a414e13a791bc7fb271b76c",
      "value": 2941
     }
    },
    "3ceff16007764ed88ce640d1c0d74741": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "47a3b3499e90463a955e17f46a2f2f08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7389a7509192486c9e04a6e8ed62beee",
      "placeholder": "​",
      "style": "IPY_MODEL_3ceff16007764ed88ce640d1c0d74741",
      "value": "Map: 100%"
     }
    },
    "69a02bfdcbf444fdbe8f55da0367d565": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69e952df5f6b4c6a8b12e9229e5c3997": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_47a3b3499e90463a955e17f46a2f2f08",
       "IPY_MODEL_3ae29d6f0cbd4a5ba0d7cb2c5d17f470",
       "IPY_MODEL_6a00776636574754a7763865838511c2"
      ],
      "layout": "IPY_MODEL_25e8cbafbbf64880b2cd04a67393711f"
     }
    },
    "6a00776636574754a7763865838511c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69a02bfdcbf444fdbe8f55da0367d565",
      "placeholder": "​",
      "style": "IPY_MODEL_d29e5203b57f40ce982460af7bae1683",
      "value": " 2941/2941 [00:01&lt;00:00, 1821.94 examples/s]"
     }
    },
    "7389a7509192486c9e04a6e8ed62beee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "998d82a07cb24a5a8bd1218f4e60e4d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d29e5203b57f40ce982460af7bae1683": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7685ee79a414e13a791bc7fb271b76c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
